from openai import AzureOpenAI

class AzureOpenAIClient:
	def __init__(self, endpoint: str, api_key: str, model: str):
		"""
		Initializes the Azure OpenAI client with the endpoint, API key, and deployment name.

		:param endpoint: The endpoint of your Azure OpenAI resource.
		:param api_key: The API key to authenticate requests.
		:param model: The name of the model deployment.
		"""
		self.endpoint = endpoint
		self.api_key = api_key
		self.model = model
		self.client = AzureOpenAI(
			api_key=self.api_key,  
			api_version='2024-08-01-preview',
			azure_endpoint=self.endpoint
		)


	def generate_response(self, user_input: str, system_message: str, temperature: float=0.7, max_tokens: int=400) -> str:
		"""
		Generates a response from the user input using the OpenAI model.

		:param user_input: str, input text provided by the user.
		:param system_message: str, system message providing context to the model.
		:param temperature: float, degree of randomness in the generated response. Higher values introduce more variability.
		:param max_tokens: int, maximum number of tokens allowed in the generated response.
		:return: str, response generated by the model.
		"""
		try:
			messages = [
				{'role': 'system', 'content': system_message},
				{'role': 'user', 'content': user_input}
			]

			response = self.client.chat.completions.create(
				model=self.model,
				temperature=temperature,
				max_tokens=max_tokens,
				messages=messages
			)

			return response.choices[0].message.content

		except Exception as e:
			return f"An error occurred while generating response: {str(e)}"
